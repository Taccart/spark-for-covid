{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d3611fb",
   "metadata": {},
   "source": [
    "# VAERS \n",
    "Data source : Vaccine Adverse Event Reporting System, U.S. Department of Health & Human Services https://vaers.hhs.gov\n",
    "\n",
    "Data files : https://vaers.hhs.gov/data/datasets.html  \n",
    "\n",
    "\n",
    "```\n",
    "VAERS is a passive reporting system, meaning it relies on individuals to send in reports of their experiences to CDC and FDA. VAERS is not designed to determine if a vaccine caused a health problem, but is especially useful for detecting unusual or unexpected patterns of adverse event reporting that might indicate a possible safety problem with a vaccine. This way, VAERS can provide CDC and FDA with valuable information that additional work and evaluation is necessary to further assess a possible safety concern.\n",
    "```\n",
    "## Content\n",
    "Data is accessible in CSV files, one per year (1990 to 2021 at this time) per dataset (data, symptoms, vaccines)\n",
    "file name are formated as `<YEAR>VAERS<DATA|SYMPTOMS|VAX>.csv` except for non domestic data named `NonDomesticVAERS<DATA|SYMPTOMS|VAX>.csv`.\n",
    "\n",
    "**Columns of CSV files are described in [VAERS DATA USE GUIDE](https://vaers.hhs.gov/docs/VAERSDataUseGuide_November2020.pdf)**\n",
    "\n",
    "## data for this notebook\n",
    "Download [All data compressed file (zip ~365MB, uncompressed ~1.5GB)](https://vaers.hhs.gov/eSubDownload/index.jsp?fn=AllVAERSDataCSVS.zip) and unzip files into dedicated dataset folders:\n",
    "```\n",
    "mkdir VAERS && \\\n",
    "cd VAERS && \\\n",
    "mkdir VAX && \\\n",
    "mkdir DATA && \\\n",
    "mkdir SYMPTOMS && \\\n",
    "unzip AllVAERSDataCSVS.zip && \\\n",
    "mv *VAERSDATA.csv DATA/ && \\\n",
    "mv *VAERSVAX.csv VAX/ && \\\n",
    "mv *VAERSSYMPTOMS.csv SYMPTOMS && \\\n",
    "echo \"CSV data dispatched.\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b202a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val sourceVAERScsvRoot=\"file:///home/taccart/Downloads/VAERS/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58c01aa-c16c-470a-a5df-eef95efcbfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "case class Symptom(\n",
    "    VAERS_ID: String\n",
    "    ,SYMPTOM: String\n",
    "    ,SYMPTOMVERSION: String\n",
    "\n",
    "case class Vax(\n",
    "    VAERS_ID: String\n",
    "    ,VAX_TYPE: String\n",
    "    ,VAX_MANU: String\n",
    "    ,VAX_LOT: String \n",
    "    ,VAX_DOSE_SERIES: String \n",
    "    ,VAX_ROUTE: String\n",
    "    ,VAX_SITE: String\n",
    "    ,VAX_NAME: String\n",
    ")\n",
    "case class Data(\n",
    "\tVAERS_ID: String\n",
    "\t,RECVDATE: String\n",
    "\t,STATE: String\n",
    "\t,AGE_YRS: String\n",
    "\t,CAGE_YR: String\n",
    "\t,CAGE_MO: String\n",
    "\t,SEX: String\n",
    "\t,RPT_DATE: String\n",
    "\t,SYMPTOM_TEXT: String\n",
    "\t,DIED: String\n",
    "\t,DATEDIED: String\n",
    "\t,L_THREAT: String\n",
    "\t,ER_VISIT: String\n",
    "\t,HOSPITAL: String\n",
    "\t,HOSPDAYS: String\n",
    "\t,X_STAY: String\n",
    "\t,DISABLE: String\n",
    "\t,RECOVD: String\n",
    "\t,VAX_DATE: String\n",
    "\t,ONSET_DATE: String\n",
    "\t,NUMDAYS: String\n",
    "\t,LAB_DATA: String\n",
    "\t,V_ADMINBY: String\n",
    "\t,V_FUNDBY: String\n",
    "\t,OTHER_MEDS: String\n",
    "\t,CUR_ILL: String\n",
    "\t,HISTORY: String\n",
    "\t,PRIOR_VAX: String\n",
    "\t,SPLTTYPE: String\n",
    "\t,FORM_VERS: String\n",
    "\t,TODAYS_DATE: String\n",
    "\t,BIRTH_DEFECT: String\n",
    "\t,OFC_VISIT: String\n",
    "\t,ER_ED_VISIT: String\n",
    "\t,ALLERGIES: String\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db48727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions._\n",
    "import org.apache.spark.sql._\n",
    "\n",
    "val symptomsCSVDF=spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .csv(s\"${sourceVAERScsvRoot}/SYMPTOMS\")\n",
    "    .withColumn(\"sourceFile\",input_file_name)\n",
    "    .cache\n",
    "\n",
    "val symptomsDF = symptomsCSVDF.where (\"SYMPTOM1 !=null\").select( \"VAERS_ID\", \"sourceFile\", \"SYMPTOM1\").withColumnRenamed(\"SYMPTOM1\",\"SYMPTOM\")\n",
    "  .unionAll(symptomsCSVDF.where (\"SYMPTOM2 !=null\").select( \"VAERS_ID\", \"sourceFile\", \"SYMPTOM2\").withColumnRenamed(\"SYMPTOM2\",\"SYMPTOM\").withColumnRenamed(\"SYMPTOMVERSION2\",\"SYMPTOMVERSION\"))\n",
    "  .unionAll(symptomsCSVDF.where (\"SYMPTOM3 !=null\").select( \"VAERS_ID\", \"sourceFile\", \"SYMPTOM3\").withColumnRenamed(\"SYMPTOM3\",\"SYMPTOM\").withColumnRenamed(\"SYMPTOMVERSION3\",\"SYMPTOMVERSION\"))\n",
    "  .unionAll(symptomsCSVDF.where (\"SYMPTOM4 !=null\").select( \"VAERS_ID\", \"sourceFile\", \"SYMPTOM4\").withColumnRenamed(\"SYMPTOM4\",\"SYMPTOM\").withColumnRenamed(\"SYMPTOMVERSION4\",\"SYMPTOMVERSION\"))\n",
    "  .unionAll(symptomsCSVDF.where (\"SYMPTOM5 !=null\").select( \"VAERS_ID\", \"sourceFile\", \"SYMPTOM5\").withColumnRenamed(\"SYMPTOM5\",\"SYMPTOM\").withColumnRenamed(\"SYMPTOMVERSION5\",\"SYMPTOMVERSION\"))\n",
    "  .cache\n",
    "println(\"Schema of symptomsDF : one row for each symptom.\")\n",
    "symptomsDF.printSchema\n",
    "symptomsDF.show\n",
    "\n",
    "val symptomsArrayDF= symptomsDF\n",
    "    .groupBy(\"VAERS_ID\",\"sourceFile\")\n",
    "    .agg(collect_list($\"SYMPTOM\")  as \"SYMPTOMS\")\n",
    "   \n",
    ".cache\n",
    "\n",
    "println(\"Schema of symptomsArrayDF: one row for each vaers_id, with the array of symptoms.\")\n",
    "symptomsArrayDF.printSchema\n",
    "\n",
    "\n",
    "val vaxDF=spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .csv(s\"${sourceVAERScsvRoot}/VAX\")\n",
    "    .withColumn(\"sourceFile\",input_file_name)\n",
    "\n",
    "    .cache\n",
    "println(\"Schema of vaxDF\")\n",
    "vaxDF.printSchema\n",
    "\n",
    "val dataDF=spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .csv(s\"${sourceVAERScsvRoot}/DATA\")\n",
    "    .withColumn(\"sourceFile\",input_file_name)\n",
    "    .cache\n",
    "println(\"Schema of dataDF\")\n",
    "dataDF.printSchema\n",
    "\n",
    "\n",
    "dataDF.createOrReplaceTempView(\"TData\")\n",
    "vaxDF.createOrReplaceTempView(\"TVax\")\n",
    "symptomsDF\n",
    "  .where (\"length(symptom) >=3\").createOrReplaceTempView(\"TSymptoms\")\n",
    "symptomsArrayDF.createOrReplaceTempView(\"TSymptomsArray\")\n",
    "println(\"SparkSQL prepared tables:\")\n",
    "spark.sql(\"show tables\").show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b57d1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "// verify presence of  VAERS_ID only in one sourceFile: this query should return no row.\n",
    "//symptomsDF.groupBy(\"VAERS_ID\",\"sourceFile\").agg(collect_list($\"SYMPTOM\")  as \"SYMPTOMS\").groupBy(\"VAERS_ID\").agg(count($\"sourceFile\")  as \"C\") .where(\"C >1\") .show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b1a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "// examples\n",
    "val fullDF= dataDF\n",
    ".join(vaxDF,dataDF.col(\"VAERS_ID\") === vaxDF.col(\"VAERS_ID\"), \"inner\")\n",
    ".join(symptomsArrayDF,dataDF.col(\"VAERS_ID\") === symptomsArrayDF.col(\"VAERS_ID\"), \"inner\")\n",
    "\n",
    "val covidDF= vaxDF\n",
    ".where(\"VAX_TYPE like 'COVI%'\")\n",
    ".select(\"VAERS_ID\",\"VAX_TYPE\", \"VAX_MANU\", \"VAX_ROUTE\")\n",
    ".join(symptomsArrayDF.select(\"VAERS_ID\", \"SYMPTOMS\"), symptomsArrayDF.col(\"VAERS_ID\" )===vaxDF.col(\"VAERS_ID\"), \"inner\")\n",
    "\n",
    ".join(dataDF, dataDF.col(\"VAERS_ID\" )===vaxDF.col(\"VAERS_ID\"), \"inner\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600bd808",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select vaers_id, symptom from tsymptoms where symptom like '%bite%'\").createOrReplaceTempView(\"tanimals\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16605e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"show tables\").show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa243414-118f-481f-a3a8-a6e0bd94458b",
   "metadata": {},
   "source": [
    "# Unexpected data\n",
    "\n",
    "## Bites: count where vax_type is COVID19 and  symptom is like bite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3ac6cb-cedd-40ea-8074-5d8ac79d0192",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import pandas as pd\n",
    "spark.sql(\"select   VAX_TYPE, VAX_MANU,symptom, count(*) reportCount from tanimals inner join tvax on tanimals.vaers_id = tvax.vaers_id where vax_type='COVID19' group by VAX_TYPE, VAX_MANU,symptom\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98e0b2c-e81c-4de7-96c7-15a41152624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select vaers_id, count(vaers_id) countSymptoms from tsymptoms group by vaers_id\")\n",
    ".cache\n",
    ".createOrReplaceTempView(\"tmanysymptoms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e62467-427b-45a9-a0d8-bc0b8006fe3f",
   "metadata": {},
   "source": [
    "##  number of reports by range of symptoms declared (by step of 10)\n",
    "99% or reports have less than 16 symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b4ddc-e95f-4242-868a-eee898538fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%python\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import pandas as pd\n",
    "spark.sql(\"select VAX_TYPE, VAX_MANU, ceil(countSymptoms/10)*10 rangeMaxSymptoms, count(*) as countReports  from tmanysymptoms  inner join tvax on tmanysymptoms.vaers_id = tvax.vaers_id where vax_type='COVID19' group by VAX_TYPE, VAX_MANU, ceil(countSymptoms/10) order by 1,2,3\") .toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a8c93-fd6b-424e-a155-b720e715f29c",
   "metadata": {},
   "source": [
    "# Quality score \n",
    "Suspicious records : \n",
    "* coming from non medical source\n",
    "* having too many symptoms declared =>  exclude the reports having a count of simultaneous symptoms in top 1% per vax.\n",
    "* suspected to be a duplicate of a previous one => \n",
    "* too much time elapsed between vax and symptom => ? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2470c625-60ea-4a45-b579-8f7eb60d49f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "// %%python\n",
    "// import numpy as np\n",
    "// import random as rand\n",
    "// import pandas as pd\n",
    "spark.sql(\"select * from tdata order by numdays desc limit 25  \") .show\n",
    "// .toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9ce6fb-9a98-4d83-9531-db6a5dd1e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(\"select symptom, count(symptom)  from x  group by symptom \").count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053e3ab9-7e28-4b47-9ae7-fbca1ac06bd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
